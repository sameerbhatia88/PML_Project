<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Activity Analysis</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<!-- rmarkdown v1 -->

<h1>Activity Analysis</h1>

<h2>Executive Summary</h2>

<p>The analysis is about classifying activities based on a number of factors. For the classification problem we will compare three algorithms:
1. Random Forest
2. Random Forest with Bagging
3. Random Forest after Dimension Rediuction</p>

<p>Dimension Reduction with Principal Component Analysis, dramatically reduces the complexity and reduces the execution time. However; the algorith compromises on the accuracy and interpretability.</p>

<ol>
<li>Data used for training and testing - <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">Training</a></li>
<li>Data for Prediction - <a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">Validation</a></li>
</ol>

<h2>Loading the Libraries</h2>

<p>First, we will load all the required libraries needed. We would use <strong>caret</strong> and <strong>party</strong> package for the analysis.</p>

<pre><code class="r">library(caret)
</code></pre>

<pre><code>## Warning: package &#39;caret&#39; was built under R version 3.1.1
</code></pre>

<pre><code>## Loading required package: lattice
## Loading required package: ggplot2
</code></pre>

<pre><code class="r">library(randomForest)
</code></pre>

<pre><code>## Warning: package &#39;randomForest&#39; was built under R version 3.1.1
</code></pre>

<pre><code>## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.
</code></pre>

<pre><code class="r">library(party)
</code></pre>

<pre><code>## Warning: package &#39;party&#39; was built under R version 3.1.1
</code></pre>

<pre><code>## Loading required package: grid
## Loading required package: zoo
## 
## Attaching package: &#39;zoo&#39;
## 
## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric
## 
## Loading required package: sandwich
</code></pre>

<pre><code>## Warning: package &#39;sandwich&#39; was built under R version 3.1.1
</code></pre>

<pre><code>## Loading required package: strucchange
</code></pre>

<pre><code>## Warning: package &#39;strucchange&#39; was built under R version 3.1.1
</code></pre>

<pre><code>## Loading required package: modeltools
</code></pre>

<pre><code>## Warning: package &#39;modeltools&#39; was built under R version 3.1.1
</code></pre>

<pre><code>## Loading required package: stats4
</code></pre>

<pre><code>## Error: cannot change working directory
</code></pre>

<h2>Importing the Datasets</h2>

<pre><code class="r">PML_Training&lt;-read.csv(&quot;pml_training.csv&quot;,header=T)

PML_Testing&lt;-read.csv(&quot;pml_testing.csv&quot;,header=T)
</code></pre>

<h2>Data Preprocessing</h2>

<p>Through some preliminary analysis, we would first select the columns which are expected to influence the prediction.</p>

<p>We would store the index of these columns in a new variable <strong>columns</strong></p>

<pre><code class="r">columns&lt;-which(names(PML_Training) %in% c(&quot;classe&quot;,
                                          &quot;num_window&quot;,
                                          &quot;roll_belt&quot;,
                                          &quot;pitch_belt&quot;,
                                          &quot;yaw_belt&quot;,
                                          &quot;total_accel_belt&quot;,
                                          &quot;gyros_belt_x&quot;,
                                          &quot;gyros_belt_y&quot;,
                                          &quot;gyros_belt_z&quot;,
                                          &quot;accel_belt_x&quot;,
                                          &quot;accel_belt_y&quot;,
                                          &quot;accel_belt_z&quot;,
                                          &quot;magnet_belt_x&quot;,
                                          &quot;magnet_belt_y&quot;,
                                          &quot;magnet_belt_z&quot;,
                                          &quot;roll_arm&quot;,
                                          &quot;pitch_arm&quot;,
                                          &quot;yaw_arm&quot;,
                                          &quot;total_accel_arm&quot;,
                                          &quot;gyros_arm_x&quot;,
                                          &quot;gyros_arm_y&quot;,
                                          &quot;gyros_arm_z&quot;,
                                          &quot;accel_arm_x&quot;,
                                          &quot;accel_arm_y&quot;,
                                          &quot;accel_arm_z&quot;,
                                          &quot;magnet_arm_x&quot;,
                                          &quot;magnet_arm_y&quot;,
                                          &quot;magnet_arm_z&quot;,
                                          &quot;roll_dumbbell&quot;,
                                          &quot;pitch_dumbbell&quot;,
                                          &quot;yaw_dumbbell&quot;))
</code></pre>

<p>The columns use for the algorith are as follows:
7, 8, 9, 10, 11, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 60, 61, 62, 63, 64, 65, 66, 67, 68, 84, 85, 86, 160</p>

<p>We will then subset the training set and partition it into training and testing sets.</p>

<pre><code class="r">PML_Training_Subset&lt;-PML_Training[,columns]
</code></pre>

<p>Training set will contain 75% of the records and testing set will contain 25% of the records.</p>

<pre><code class="r">inTrain&lt;-createDataPartition(y=PML_Training_Subset$classe,p=0.75,list=FALSE)
training&lt;-PML_Training_Subset[inTrain,]
testing&lt;-PML_Training_Subset[-inTrain,]
</code></pre>

<h2>Simple Random Forrest</h2>

<p><strong>Step 1: Training The Model</strong>
We will first train the model on the training set using all the predictors. The output variable is <strong>classe</strong></p>

<pre><code class="r">r2 = randomForest(classe ~., data=training, importance=TRUE, do.trace=100)
</code></pre>

<pre><code>## ntree      OOB      1      2      3      4      5
##   100:   0.37%  0.12%  0.28%  0.55%  0.79%  0.30%
##   200:   0.35%  0.12%  0.18%  0.55%  0.75%  0.37%
##   300:   0.35%  0.10%  0.14%  0.66%  0.70%  0.37%
##   400:   0.33%  0.12%  0.07%  0.62%  0.62%  0.37%
##   500:   0.31%  0.10%  0.07%  0.62%  0.54%  0.37%
</code></pre>

<p><strong>Step 2: FOt the Model on the Training Set:</strong></p>

<pre><code class="r">pred2&lt;-predict(r2,testing[,-31])
</code></pre>

<p><strong>Step 3: Building the Confusion Matrix to asses the accuracy of the Model</strong></p>

<pre><code class="r">r2
</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = classe ~ ., data = training, importance = TRUE,      do.trace = 100) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 5
## 
##         OOB estimate of  error rate: 0.31%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 4181    0    1    3    0   0.0009558
## B    1 2846    1    0    0   0.0007022
## C    0   14 2551    2    0   0.0062330
## D    0    0   12 2399    1   0.0053897
## E    0    2    1    7 2696   0.0036955
</code></pre>

<pre><code class="r">confusionMatrix(testing$classe,pred2)
</code></pre>

<pre><code>## Warning: package &#39;e1071&#39; was built under R version 3.1.1
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1393    1    0    1    0
##          B    0  946    0    3    0
##          C    0    4  849    1    1
##          D    1    0    4  799    0
##          E    0    0    0    0  901
## 
## Overall Statistics
##                                         
##                Accuracy : 0.997         
##                  95% CI : (0.995, 0.998)
##     No Information Rate : 0.284         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.996         
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             0.999    0.995    0.995    0.994    0.999
## Specificity             0.999    0.999    0.999    0.999    1.000
## Pos Pred Value          0.999    0.997    0.993    0.994    1.000
## Neg Pred Value          1.000    0.999    0.999    0.999    1.000
## Prevalence              0.284    0.194    0.174    0.164    0.184
## Detection Rate          0.284    0.193    0.173    0.163    0.184
## Detection Prevalence    0.284    0.194    0.174    0.164    0.184
## Balanced Accuracy       0.999    0.997    0.997    0.996    0.999
</code></pre>

<p>OOB estimate of  error rate = 0.26%.
Accuracy of the model = 99.76%</p>

<p><strong>Plot of the Error Rate vs Number of Trees used</strong></p>

<pre><code class="r">plot(r2, log=&quot;y&quot;,main=&quot;Simple Random Forrest&quot;)
legend(&quot;topright&quot;, colnames(r2$err.rate),col=1:6,cex=0.8,fill=1:6)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-10"/> 
The above plot shows that classifying <strong>Activity Type D</strong> has highest error rate.</p>

<p><strong>Importance of Variables</strong></p>

<pre><code class="r">VariableUsed&lt;-varUsed(r2, by.tree=FALSE, count=TRUE)
Max_Imp=names(PML_Training_Subset)[which(VariableUsed==max(VariableUsed))]
Min_Imp=names(PML_Training_Subset)[which(VariableUsed==min(VariableUsed))]
</code></pre>

<p>Variable Used the most <strong>num_window</strong>
Variable used the least <strong>total_accel_belt</strong></p>

<h2>Random Forrest with Bagging</h2>

<pre><code class="r">predictors&lt;-PML_Training_Subset[,-31]
Classe&lt;-PML_Training_Subset[,31]
treeBag&lt;-bag(predictors,Classe,B=10,
             bagControl=bagControl(fit=ctreeBag$fit,
                                   predict=ctreeBag$pred,
                                   aggregate=ctreeBag$aggregate))


pred3&lt;-predict(treeBag,testing[,-31])

confusionMatrix(testing$classe,pred3)
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1380   10    3    1    1
##          B   10  920   14    3    2
##          C    6   12  834    1    2
##          D    2    2   26  772    2
##          E    0    3    0    2  896
## 
## Overall Statistics
##                                         
##                Accuracy : 0.979         
##                  95% CI : (0.975, 0.983)
##     No Information Rate : 0.285         
##     P-Value [Acc &gt; NIR] : &lt; 2e-16       
##                                         
##                   Kappa : 0.974         
##  Mcnemar&#39;s Test P-Value : 0.00178       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             0.987    0.971    0.951    0.991    0.992
## Specificity             0.996    0.993    0.995    0.992    0.999
## Pos Pred Value          0.989    0.969    0.975    0.960    0.994
## Neg Pred Value          0.995    0.993    0.989    0.998    0.998
## Prevalence              0.285    0.193    0.179    0.159    0.184
## Detection Rate          0.281    0.188    0.170    0.157    0.183
## Detection Prevalence    0.284    0.194    0.174    0.164    0.184
## Balanced Accuracy       0.991    0.982    0.973    0.992    0.995
</code></pre>

<p>Confusion Matrix of the bagged model shows accuracy of 98.06%</p>

<h2>Random Forrest with PCA</h2>

<p><strong>Step 1:</strong>
Create Principal Components and determine the number of components to be use</p>

<pre><code class="r">prComp&lt;-prcomp(training[,-31],center=T,scale=T)
</code></pre>

<p>We will now calculate Eigen Values and components with eigen value greater than one will be used.</p>

<pre><code class="r">Eigen_Values=prComp$sdev^2
Eigen_Values
</code></pre>

<pre><code>##  [1] 7.164588 4.896200 4.018763 2.066795 1.899472 1.622989 1.402488
##  [8] 1.177047 0.963959 0.823242 0.703494 0.648525 0.479894 0.368907
## [15] 0.326597 0.295824 0.269906 0.218827 0.168478 0.129478 0.087554
## [22] 0.061008 0.046543 0.037563 0.035236 0.032277 0.024807 0.020321
## [29] 0.006877 0.002342
</code></pre>

<pre><code class="r">No_of_comp=sum(Eigen_Values&gt;1)
</code></pre>

<p>Eigen Value calculation shows that we should use <strong>8</strong> components.</p>

<p>We will also create screeplot to see after how many components variance plot flattens</p>

<pre><code class="r">screeplot(prComp,main=&quot;Scree Plot&quot;,xlab=&quot;Components&quot;)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-15"/> </p>

<pre><code class="r">screeplot(prComp,type=&quot;line&quot;,main=&quot;Scree  Plot&quot;)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-15"/> 
The Plot shows that after 10 components, variance flattens.</p>

<p>We will take the middle path and go with 9 components.</p>

<p>Varimax Rotation shows loading of different variables on these components</p>

<pre><code class="r">summary(prComp)
</code></pre>

<pre><code>## Importance of components:
##                          PC1   PC2   PC3    PC4    PC5    PC6    PC7
## Standard deviation     2.677 2.213 2.005 1.4376 1.3782 1.2740 1.1843
## Proportion of Variance 0.239 0.163 0.134 0.0689 0.0633 0.0541 0.0467
## Cumulative Proportion  0.239 0.402 0.536 0.6049 0.6682 0.7223 0.7690
##                           PC8    PC9   PC10   PC11   PC12  PC13   PC14
## Standard deviation     1.0849 0.9818 0.9073 0.8387 0.8053 0.693 0.6074
## Proportion of Variance 0.0392 0.0321 0.0274 0.0234 0.0216 0.016 0.0123
## Cumulative Proportion  0.8083 0.8404 0.8679 0.8913 0.9129 0.929 0.9412
##                          PC15    PC16  PC17    PC18    PC19    PC20
## Standard deviation     0.5715 0.54390 0.520 0.46779 0.41046 0.35983
## Proportion of Variance 0.0109 0.00986 0.009 0.00729 0.00562 0.00432
## Cumulative Proportion  0.9521 0.96196 0.971 0.97825 0.98387 0.98818
##                           PC21    PC22    PC23    PC24    PC25    PC26
## Standard deviation     0.29589 0.24700 0.21574 0.19381 0.18771 0.17966
## Proportion of Variance 0.00292 0.00203 0.00155 0.00125 0.00117 0.00108
## Cumulative Proportion  0.99110 0.99313 0.99469 0.99594 0.99711 0.99819
##                           PC27    PC28    PC29    PC30
## Standard deviation     0.15750 0.14255 0.08293 0.04840
## Proportion of Variance 0.00083 0.00068 0.00023 0.00008
## Cumulative Proportion  0.99902 0.99969 0.99992 1.00000
</code></pre>

<pre><code class="r">load = prComp$rotation
my.var=varimax(load)
my.var
</code></pre>

<pre><code>## $loadings
## 
## Loadings:
##                  PC1 PC2 PC3 PC4 PC5 PC6 PC7 PC8 PC9 PC10 PC11 PC12 PC13
## num_window                                       -1                     
## roll_belt                                                               
## pitch_belt                                                              
## yaw_belt                                                                
## total_accel_belt                                                        
## gyros_belt_x                                          1                 
## gyros_belt_y                                                            
## gyros_belt_z                             -1                             
## accel_belt_x          1                                                 
## accel_belt_y                                                            
## accel_belt_z                                                            
## magnet_belt_x                                                           
## magnet_belt_y                    -1                                     
## magnet_belt_z                                                           
## roll_arm                                                                
## pitch_arm                                                           -1  
## yaw_arm                                                    1            
## total_accel_arm                      -1                                 
## gyros_arm_x                   1                                         
## gyros_arm_y                                                             
## gyros_arm_z                                                             
## accel_arm_x                                                             
## accel_arm_y       1                                                     
## accel_arm_z                                                             
## magnet_arm_x                                                            
## magnet_arm_y                                                            
## magnet_arm_z              1                                             
## roll_dumbbell                                                   1       
## pitch_dumbbell                               -1                         
## yaw_dumbbell                                                            
##                  PC14 PC15 PC16 PC17 PC18 PC19 PC20 PC21 PC22 PC23 PC24
## num_window                                                             
## roll_belt                                                              
## pitch_belt                                                             
## yaw_belt                                                               
## total_accel_belt                                                       
## gyros_belt_x                                                           
## gyros_belt_y                               1                           
## gyros_belt_z                                                           
## accel_belt_x                                                           
## accel_belt_y                                                   1       
## accel_belt_z                                                           
## magnet_belt_x                                        1                 
## magnet_belt_y                                                          
## magnet_belt_z                         1                                
## roll_arm               1                                               
## pitch_arm                                                              
## yaw_arm                                                                
## total_accel_arm                                                        
## gyros_arm_x                                                            
## gyros_arm_y                                              -1            
## gyros_arm_z      -1                                                    
## accel_arm_x                                                         1  
## accel_arm_y                                                            
## accel_arm_z                                                            
## magnet_arm_x               -1                                          
## magnet_arm_y                                    1                      
## magnet_arm_z                                                           
## roll_dumbbell                                                          
## pitch_dumbbell                                                         
## yaw_dumbbell                     1                                     
##                  PC25 PC26 PC27 PC28 PC29 PC30
## num_window                                    
## roll_belt                                  1  
## pitch_belt                 -1                 
## yaw_belt          1                           
## total_accel_belt                -1            
## gyros_belt_x                                  
## gyros_belt_y                                  
## gyros_belt_z                                  
## accel_belt_x                                  
## accel_belt_y                                  
## accel_belt_z                          1       
## magnet_belt_x                                 
## magnet_belt_y                                 
## magnet_belt_z                                 
## roll_arm                                      
## pitch_arm                                     
## yaw_arm                                       
## total_accel_arm                               
## gyros_arm_x                                   
## gyros_arm_y                                   
## gyros_arm_z                                   
## accel_arm_x                                   
## accel_arm_y                                   
## accel_arm_z           -1                      
## magnet_arm_x                                  
## magnet_arm_y                                  
## magnet_arm_z                                  
## roll_dumbbell                                 
## pitch_dumbbell                                
## yaw_dumbbell                                  
## 
##                  PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8   PC9  PC10
## SS loadings    1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000
## Proportion Var 0.033 0.033 0.033 0.033 0.033 0.033 0.033 0.033 0.033 0.033
## Cumulative Var 0.033 0.067 0.100 0.133 0.167 0.200 0.233 0.267 0.300 0.333
##                 PC11  PC12  PC13  PC14  PC15  PC16  PC17  PC18  PC19  PC20
## SS loadings    1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000
## Proportion Var 0.033 0.033 0.033 0.033 0.033 0.033 0.033 0.033 0.033 0.033
## Cumulative Var 0.367 0.400 0.433 0.467 0.500 0.533 0.567 0.600 0.633 0.667
##                 PC21  PC22  PC23  PC24  PC25  PC26  PC27  PC28  PC29  PC30
## SS loadings    1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000
## Proportion Var 0.033 0.033 0.033 0.033 0.033 0.033 0.033 0.033 0.033 0.033
## Cumulative Var 0.700 0.733 0.767 0.800 0.833 0.867 0.900 0.933 0.967 1.000
## 
## $rotmat
##             [,1]       [,2]      [,3]      [,4]     [,5]       [,6]
##  [1,]  0.3040484 -0.2060639  0.009974 -0.050233 -0.04187 -0.1093807
##  [2,]  0.1368716  0.2905509  0.137559  0.049023 -0.16861 -0.0409137
##  [3,]  0.1628888 -0.1127924  0.435419 -0.022167  0.05644  0.1139501
##  [4,] -0.0536081 -0.2433279 -0.001651  0.464838 -0.31495 -0.0886735
##  [5,]  0.0941386  0.1344642  0.017967  0.481399  0.40171  0.0280420
##  [6,]  0.1371141  0.0474891  0.193515  0.087486 -0.23298  0.5713966
##  [7,] -0.0008985  0.0760982 -0.120088  0.095182 -0.18281 -0.3011907
##  [8,]  0.0542221  0.0338713 -0.072643  0.057177 -0.20470 -0.0002667
##  [9,]  0.0494666 -0.0295826  0.036291  0.071821  0.10882  0.1422545
## [10,]  0.0922655  0.0005979  0.019420  0.050034  0.20972  0.1269265
## [11,] -0.0005016 -0.0497300  0.036806 -0.039749  0.04406  0.0789299
## [12,]  0.1252481 -0.0338294 -0.078538  0.051747 -0.01773 -0.1599165
## [13,]  0.0783276  0.1660308  0.036428  0.048209 -0.06603 -0.0657483
## [14,] -0.0555150  0.0535147 -0.036835  0.176499  0.02697 -0.0734058
## [15,] -0.0366835 -0.2127095 -0.058928  0.051371  0.13798  0.0239990
## [16,] -0.2473620  0.0101660 -0.097703  0.093408 -0.19083  0.4694295
## [17,] -0.1444586  0.0530578 -0.090445  0.012377  0.09123  0.3745675
## [18,] -0.0479757 -0.1096949 -0.136076 -0.049332  0.34251  0.2178537
## [19,]  0.0743541 -0.0746619 -0.001631  0.041144  0.41130 -0.0101482
## [20,]  0.3596865 -0.0795516 -0.320974 -0.007780 -0.26068  0.2349619
## [21,] -0.3032676 -0.1149719  0.395288  0.092606 -0.21149 -0.0672747
## [22,]  0.0423013 -0.0662467 -0.105059 -0.575949 -0.10345  0.0201632
## [23,] -0.0479419  0.5330175 -0.065669 -0.063256  0.11575  0.0057541
## [24,] -0.0299414 -0.0293661  0.088749 -0.314515  0.08705  0.0124936
## [25,]  0.3540120 -0.1773036 -0.325790  0.134603  0.01389  0.0127470
## [26,] -0.0283351 -0.1429965  0.402706 -0.024364  0.06014  0.0004111
## [27,] -0.0632713 -0.5011950  0.031740 -0.047446  0.09638 -0.0108139
## [28,] -0.3185266 -0.2427975 -0.260962  0.034859 -0.01926 -0.0039156
## [29,] -0.4936010  0.0477656 -0.249199  0.016014  0.01238 -0.0150818
## [30,]  0.0123584 -0.0004341  0.016566 -0.005639  0.07106  0.0012887
##             [,7]      [,8]       [,9]     [,10]      [,11]      [,12]
##  [1,] -0.1150338 -0.021456  0.0592889 -0.052656  0.1180396 -0.0141471
##  [2,] -0.2165670  0.213571 -0.0874146  0.280415 -0.0582387  0.1746349
##  [3,]  0.1087156  0.008586  0.0333713 -0.153970  0.0354821 -0.1151949
##  [4,] -0.0749509  0.073283 -0.1310657  0.018255 -0.1649310 -0.0518378
##  [5,] -0.0903155 -0.110415  0.0989621  0.008400  0.2580263 -0.0438516
##  [6,]  0.0147320 -0.184458 -0.0438214 -0.026816  0.1103444  0.2715367
##  [7,]  0.4402652 -0.223090  0.3002585 -0.212461 -0.0540810  0.3548052
##  [8,]  0.1182160  0.602330 -0.0385713 -0.267820  0.2552309 -0.4580916
##  [9,] -0.1595359  0.204521  0.6861877 -0.086922 -0.4715512 -0.0417334
## [10,]  0.4079643  0.179006 -0.4746396  0.116484 -0.3361983  0.0952492
## [11,]  0.2444114  0.059934  0.3584241  0.342015  0.4905375 -0.0333900
## [12,] -0.1929027  0.067190 -0.1360912 -0.430395  0.2921456  0.4414377
## [13,] -0.0108559 -0.132759 -0.0244402 -0.196630 -0.3316355 -0.2053436
## [14,] -0.0584208 -0.116078 -0.0502668  0.328979  0.1154926 -0.1841627
## [15,] -0.0238964  0.288620  0.0579465  0.334800 -0.1042669  0.3831605
## [16,]  0.2160822 -0.197431  0.0285705 -0.089459  0.0466608 -0.0885661
## [17,] -0.0722014  0.414763  0.0252101 -0.211327  0.0354085  0.2573471
## [18,] -0.3931000 -0.254997 -0.1129082 -0.181973 -0.0127259 -0.1301379
## [19,]  0.4433706  0.005622 -0.0118765 -0.213797 -0.0124531 -0.0559420
## [20,]  0.0722243 -0.108477  0.0326801  0.142274 -0.0829646 -0.1211229
## [21,] -0.0337042 -0.024327  0.0052409 -0.099883  0.0162916  0.0266571
## [22,] -0.0348401 -0.021832  0.0248921 -0.079032  0.0230491 -0.0036229
## [23,] -0.0047177  0.047442  0.0198862 -0.010150  0.0062319  0.0173085
## [24,]  0.0342187  0.035111 -0.0297001  0.136937 -0.0135503  0.0305403
## [25,] -0.0258783  0.006736 -0.0032420 -0.035545  0.0091370  0.0322968
## [26,] -0.0148746 -0.013773 -0.0002479 -0.057691 -0.0078799 -0.0007348
## [27,]  0.0175470  0.012772 -0.0087748  0.051159  0.0052420 -0.0066474
## [28,] -0.0169498  0.022789 -0.0127928  0.005998  0.0027965  0.0155602
## [29,]  0.0074134 -0.003550 -0.0008194 -0.021627  0.0017297 -0.0123223
## [30,]  0.0000959  0.002308 -0.0015517 -0.007838  0.0005872  0.0044940
##           [,13]      [,14]     [,15]     [,16]     [,17]     [,18]
##  [1,]  0.023009  0.2603088  0.171593  0.060700  0.091081 -0.022774
##  [2,] -0.155706 -0.0464163 -0.104661  0.159687 -0.341265  0.167914
##  [3,] -0.296464  0.0544152 -0.033729  0.347869  0.079517 -0.054356
##  [4,]  0.038079 -0.2365114 -0.184560  0.056049  0.079656  0.311838
##  [5,] -0.024986 -0.1066317  0.273493  0.037827  0.015928 -0.384750
##  [6,]  0.110374  0.0593087  0.121322 -0.356573  0.021818  0.240131
##  [7,] -0.206373  0.0420321  0.090784  0.119955 -0.017928  0.206102
##  [8,] -0.037145  0.1176381  0.187400 -0.104889 -0.232345  0.099442
##  [9,] -0.046782  0.0930233 -0.285986 -0.152386 -0.155716 -0.121169
## [10,]  0.071310  0.0070706 -0.271054 -0.082482 -0.116510 -0.269077
## [11,]  0.449203 -0.1919913 -0.331617  0.064352 -0.072931  0.101252
## [12,]  0.173034  0.2096675 -0.387230 -0.018717 -0.212848 -0.220264
## [13,]  0.724962  0.2275246  0.134833  0.205332  0.096404  0.042642
## [14,] -0.167656  0.7196333 -0.324270 -0.042100  0.244617  0.130673
## [15,]  0.128939  0.2982864  0.486852  0.061159 -0.209903  0.088728
## [16,] -0.079504  0.2525431  0.010595  0.255701 -0.368102 -0.173660
## [17,] -0.012134 -0.0065601 -0.058967  0.265026  0.593846  0.082460
## [18,] -0.033478 -0.0753950 -0.073460  0.135644 -0.302170  0.394380
## [19,] -0.020062  0.0683724 -0.048310 -0.086366 -0.055439  0.363677
## [20,] -0.061080 -0.0963722 -0.008943  0.029423  0.104434 -0.220974
## [21,]  0.075040  0.0203496 -0.011087  0.156734 -0.083096 -0.172300
## [22,] -0.026413  0.0807261 -0.002160 -0.137159  0.014563 -0.071826
## [23,] -0.006564  0.0090711  0.014736 -0.064030 -0.007762  0.125635
## [24,]  0.024948 -0.0045607 -0.027595  0.406874 -0.047237  0.014216
## [25,] -0.012005 -0.0209218 -0.045382  0.061608 -0.028470  0.005532
## [26,]  0.006485  0.0399861  0.033056 -0.450017  0.044727 -0.018935
## [27,]  0.029623  0.0016174 -0.005295  0.046240 -0.003129  0.026941
## [28,]  0.001321 -0.0006325  0.015424 -0.118509  0.001246 -0.051705
## [29,]  0.003945 -0.0033519  0.004920 -0.112401  0.015121 -0.107823
## [30,]  0.003190  0.0012525  0.006705 -0.002771  0.002281  0.024051
##           [,19]     [,20]     [,21]     [,22]      [,23]     [,24]
##  [1,] -0.228132  0.032347 -0.226319 -0.122936 -0.2842506 -0.055096
##  [2,]  0.129129  0.147566  0.258003  0.015161 -0.2305196 -0.313783
##  [3,] -0.055211  0.438060 -0.073191 -0.029352  0.1353989 -0.268757
##  [4,]  0.070048  0.068690 -0.231006  0.451976  0.0707363 -0.043667
##  [5,] -0.034990  0.006997  0.128605  0.449390 -0.0829314 -0.006005
##  [6,] -0.046125 -0.028669  0.018428  0.102364 -0.0610156  0.190891
##  [7,] -0.378353  0.093212  0.125799  0.106980 -0.0070723  0.075229
##  [8,] -0.173197  0.018846  0.083575  0.066650  0.0140104  0.190909
##  [9,] -0.015343 -0.042908 -0.035953  0.058828 -0.0506866  0.110464
## [10,] -0.419579 -0.014374  0.011404  0.063257 -0.0622279  0.007786
## [11,] -0.178502  0.079658  0.017092 -0.029299  0.0004735 -0.137712
## [12,]  0.181138  0.187283 -0.040583  0.024938  0.0471183  0.131275
## [13,]  0.011454  0.158303  0.083307  0.046169 -0.0289964 -0.135203
## [14,] -0.056120 -0.035193  0.133972  0.102958  0.0497689  0.070407
## [15,]  0.031456  0.094833  0.033721  0.019177  0.1707631 -0.037679
## [16,]  0.147706 -0.105909 -0.295877  0.009525 -0.0161363 -0.191187
## [17,] -0.060939 -0.064674  0.109755 -0.026975 -0.0581541 -0.092514
## [18,] -0.381947  0.092916  0.210476 -0.030623  0.0203925  0.064023
## [19,]  0.526937 -0.051685  0.240059  0.015045 -0.1159115 -0.066575
## [20,]  0.166281  0.381804  0.415537 -0.069690  0.1673346  0.217972
## [21,] -0.060243 -0.330500  0.530304 -0.077077  0.2585253  0.056495
## [22,] -0.040593 -0.110566  0.166577  0.633128 -0.0002325 -0.362386
## [23,] -0.027136  0.163761 -0.209432  0.048538  0.5924783  0.016760
## [24,]  0.111937  0.026201 -0.108024  0.313327  0.0460269  0.526274
## [25,] -0.040649 -0.359524 -0.004251 -0.104360  0.4404285 -0.327371
## [26,] -0.035489  0.244450 -0.004747  0.002597  0.2251517 -0.138563
## [27,]  0.051274  0.060099 -0.065924  0.048375  0.2258275  0.094836
## [28,] -0.027634  0.310910  0.073434 -0.040373 -0.1689998 -0.086790
## [29,] -0.001519  0.284766  0.062700 -0.010182  0.0308190 -0.129736
## [30,] -0.005020 -0.008291 -0.044892  0.004603  0.0090094 -0.004995
##           [,25]     [,26]     [,27]     [,28]     [,29]     [,30]
##  [1,] -0.345611  0.094980 -0.191936  0.327330  0.332973 -0.343254
##  [2,]  0.070091  0.055256  0.298576  0.158067  0.165639 -0.137303
##  [3,]  0.005468 -0.379835 -0.111041 -0.110003 -0.105761  0.096562
##  [4,] -0.134805  0.080275 -0.241838 -0.008669  0.027041 -0.011080
##  [5,]  0.010252  0.015027  0.106035  0.059873  0.011485 -0.040474
##  [6,]  0.022029 -0.378120  0.081675  0.054090  0.069233 -0.052888
##  [7,]  0.111078  0.112566  0.136806 -0.018250  0.012255  0.008278
##  [8,]  0.092353 -0.028188  0.074808 -0.037891  0.005155  0.021596
##  [9,] -0.034101 -0.091158 -0.011978  0.028895  0.024727 -0.029787
## [10,] -0.090177 -0.009589 -0.021103  0.032635  0.034651 -0.049437
## [11,] -0.027539  0.037534 -0.081173 -0.019275 -0.008615  0.007514
## [12,] -0.014226  0.004500 -0.038504 -0.093612 -0.042482  0.053220
## [13,]  0.120683 -0.036928  0.161460  0.002976 -0.016570  0.018929
## [14,]  0.062663 -0.019515  0.035656 -0.034864 -0.037289  0.046496
## [15,] -0.054838  0.019911 -0.250325 -0.196645 -0.115496  0.110629
## [16,]  0.002453  0.312681  0.030070  0.041536  0.002183 -0.002667
## [17,]  0.030659  0.236247  0.071144  0.020106  0.016809 -0.029513
## [18,] -0.016197  0.133974 -0.100493 -0.080879 -0.028725  0.006212
## [19,] -0.133613 -0.004207 -0.124316  0.118492  0.074851 -0.113839
## [20,] -0.121989  0.216059 -0.103736 -0.030663  0.068912  0.004996
## [21,] -0.237445 -0.045426 -0.154523  0.201003  0.075164 -0.047678
## [22,] -0.131527 -0.008978 -0.041194 -0.052102 -0.041517  0.046306
## [23,] -0.391579  0.011724  0.033259  0.287313 -0.017399 -0.077064
## [24,]  0.385050 -0.051374 -0.104989  0.298345  0.134906 -0.141050
## [25,]  0.396215 -0.224139 -0.005791  0.203911  0.092322 -0.088903
## [26,]  0.407082  0.517921 -0.042170  0.146504  0.072709 -0.086786
## [27,] -0.226975 -0.002184  0.745528 -0.104412  0.121997 -0.138126
## [28,]  0.027028 -0.201041  0.070660  0.649713 -0.321046  0.199472
## [29,]  0.136478 -0.293661 -0.137653 -0.226035  0.514783 -0.351132
## [30,] -0.037821  0.016676  0.027552  0.104858  0.625998  0.765623
</code></pre>

<p>Cumulative variance equals 1, if we use al the 30 components. However, we decide to use 9 components.</p>

<p><strong>Step 2: Pre-processing to Compute Components</strong></p>

<pre><code class="r">preProc&lt;-preProcess(training[,-31],method=&quot;pca&quot;,pcaComp=9)
</code></pre>

<p><strong>Step 3: Train the PCA Model on Train set and apply on Test set</strong></p>

<pre><code class="r">trainPC&lt;-predict(preProc,training[,-31])
testPC&lt;-predict(preProc,testing[,-31])
</code></pre>

<p><strong>Step 4: Fit Random Forest on trainPC</strong></p>

<pre><code class="r">r = randomForest(training$classe ~., data=trainPC, importance=TRUE, do.trace=100)
</code></pre>

<pre><code>## ntree      OOB      1      2      3      4      5
##   100:   8.28%  6.48% 10.81%  8.61% 11.57%  5.14%
##   200:   7.81%  6.38% 10.36%  7.87% 11.28%  4.21%
##   300:   7.63%  6.07% 10.11%  7.75% 11.03%  4.29%
##   400:   7.57%  6.14%  9.83%  7.60% 11.11%  4.21%
##   500:   7.51%  6.12%  9.83%  7.71% 10.86%  4.03%
</code></pre>

<p><strong>Step 5: Fit the trained model on training set</strong></p>

<pre><code class="r">pred&lt;-predict(r,testPC)
</code></pre>

<p>We will now construct the Confusion Matrix to assess the accuracy of the Model</p>

<pre><code class="r">confusionMatrix(testing$classe,pred)
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1317   40   14   21    3
##          B   33  865   38    9    4
##          C   22   23  791   14    5
##          D   13   13   52  720    6
##          E    3   16    4   17  861
## 
## Overall Statistics
##                                         
##                Accuracy : 0.929         
##                  95% CI : (0.921, 0.936)
##     No Information Rate : 0.283         
##     P-Value [Acc &gt; NIR] : &lt; 2e-16       
##                                         
##                   Kappa : 0.91          
##  Mcnemar&#39;s Test P-Value : 4.58e-06      
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             0.949    0.904    0.880    0.922    0.980
## Specificity             0.978    0.979    0.984    0.980    0.990
## Pos Pred Value          0.944    0.911    0.925    0.896    0.956
## Neg Pred Value          0.980    0.977    0.973    0.985    0.996
## Prevalence              0.283    0.195    0.183    0.159    0.179
## Detection Rate          0.269    0.176    0.161    0.147    0.176
## Detection Prevalence    0.284    0.194    0.174    0.164    0.184
## Balanced Accuracy       0.963    0.941    0.932    0.951    0.985
</code></pre>

<pre><code class="r">r
</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = training$classe ~ ., data = trainPC, importance = TRUE,      do.trace = 100) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 7.51%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 3929  107   66   58   25     0.06117
## B  121 2568  102   33   24     0.09831
## C   58   83 2369   43   14     0.07713
## D   32   72  128 2150   30     0.10862
## E    9   38   23   39 2597     0.04028
</code></pre>

<p>Accuracy of the Model = 92.31%
OOB estimate of  error rate = 7.37%</p>

<p><strong>Plot of the Error Rate vs Number of Trees used</strong></p>

<pre><code class="r">plot(r, log=&quot;y&quot;,main=&quot;Random Forrest with PCA&quot;)
legend(&quot;topright&quot;, colnames(r$err.rate),col=1:6,cex=0.8,fill=1:6)
</code></pre>

<p><img src="data:image/png;base64,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" alt="plot of chunk unnamed-chunk-22"/> 
The above plot shows that classifying <strong>Activity Type D</strong> has highest error rate.</p>

<p><strong>Importance of Variables</strong></p>

<pre><code class="r">VariableUsedPCA&lt;-varUsed(r, by.tree=FALSE, count=TRUE)
Max_ImpPCA=names(testPC)[which(VariableUsedPCA==max(VariableUsedPCA))]
Min_ImpPCA=names(testPC)[which(VariableUsedPCA==min(VariableUsedPCA))]
</code></pre>

<p>Component Used the most <strong>PC9</strong>
Component used the least <strong>PC6</strong></p>

<h2>Model Selection and Prediction</h2>

<p>Since, Simple Random Forest gives us the highest accuracy, we will use this model to classify the activities in the Second Dataset.</p>

<p><strong>Step 1: Subset the Dataset to be predicted</strong></p>

<pre><code class="r">columns_PML_TEST&lt;-which(names(PML_Testing) %in% c(&quot;num_window&quot;,
                                          &quot;roll_belt&quot;,
                                          &quot;pitch_belt&quot;,
                                          &quot;yaw_belt&quot;,
                                          &quot;total_accel_belt&quot;,
                                          &quot;gyros_belt_x&quot;,
                                          &quot;gyros_belt_y&quot;,
                                          &quot;gyros_belt_z&quot;,
                                          &quot;accel_belt_x&quot;,
                                          &quot;accel_belt_y&quot;,
                                          &quot;accel_belt_z&quot;,
                                          &quot;magnet_belt_x&quot;,
                                          &quot;magnet_belt_y&quot;,
                                          &quot;magnet_belt_z&quot;,
                                          &quot;roll_arm&quot;,
                                          &quot;pitch_arm&quot;,
                                          &quot;yaw_arm&quot;,
                                          &quot;total_accel_arm&quot;,
                                          &quot;gyros_arm_x&quot;,
                                          &quot;gyros_arm_y&quot;,
                                          &quot;gyros_arm_z&quot;,
                                          &quot;accel_arm_x&quot;,
                                          &quot;accel_arm_y&quot;,
                                          &quot;accel_arm_z&quot;,
                                          &quot;magnet_arm_x&quot;,
                                          &quot;magnet_arm_y&quot;,
                                          &quot;magnet_arm_z&quot;,
                                          &quot;roll_dumbbell&quot;,
                                          &quot;pitch_dumbbell&quot;,
                                          &quot;yaw_dumbbell&quot;))
</code></pre>

<p><strong>Step 2: Predict Activities based on Simple Random Forest Model</strong></p>

<pre><code class="r">pred_rf&lt;-predict(r2,PML_Testing[,columns_PML_TEST])
</code></pre>

<p>Just for comparison, we will compare predictions of all the models</p>

<pre><code class="r">predictPC&lt;-predict(preProc,PML_Testing[,columns_PML_TEST])

pred_rf_pca&lt;-predict(r,predictPC)

pred_treeBag&lt;-predict(treeBag,PML_Testing[,columns_PML_TEST])

Combined_Prediction_DS=data.frame(RandomForest=pred_rf,RF_PCA=pred_rf_pca,TreeBag=pred_treeBag)

Combined_Prediction_DS
</code></pre>

<pre><code>##    RandomForest RF_PCA TreeBag
## 1             B      B       B
## 2             A      C       A
## 3             B      C       B
## 4             A      A       A
## 5             A      A       A
## 6             E      E       E
## 7             D      D       D
## 8             B      B       B
## 9             A      A       A
## 10            A      A       A
## 11            B      B       B
## 12            C      C       C
## 13            B      B       B
## 14            A      A       A
## 15            E      E       E
## 16            E      E       E
## 17            A      A       A
## 18            B      B       B
## 19            B      B       B
## 20            B      B       B
</code></pre>

</body>

</html>

